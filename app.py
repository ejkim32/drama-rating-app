import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import ast
import matplotlib
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer,PolynomialFeatures, StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, RandomizedSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import MultiLabelBinarizer
import scipy.stats as stats
from sklearn.ensemble      import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows: Malgun Gothic, macOS/LinuxëŠ” ì ì ˆí•œ í•œê¸€ í°íŠ¸ë¡œ)
# 1) ì‚¬ìš©í•  í•œê¸€ í°íŠ¸ ì´ë¦„ ì„¤ì •
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
matplotlib.rcParams['axes.unicode_minus'] = False 

class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):
    """ë¦¬ìŠ¤íŠ¸í˜• ë©€í‹°ì¹´í…Œê³ ë¦¬(ì˜ˆ: ['ë¡œë§¨ìŠ¤','ìŠ¤ë¦´ëŸ¬'])ë¥¼ ì´ì§„ ë²¡í„°ë¡œ ë³€í™˜"""
    def __init__(self):
        self.mlb = MultiLabelBinarizer()
    def fit(self, X, y=None):
        # X: 2D array or DataFrame of lists
        lists = X.squeeze()  # í•œ ê°œ ì»¬ëŸ¼ì´ë©´ Seriesë¡œ ë³€í™˜
        self.mlb.fit(lists)
        return self
    def transform(self, X):
        lists = X.squeeze()
        return self.mlb.transform(lists)

def clean_cell(x):
    if isinstance(x, list):
        return x
    if pd.isna(x):
        return []
    if isinstance(x, str):
        try:
            return ast.literal_eval(x)
        except:
            return [x.strip()]
    return [str(x)]

# =========================
# 0. í˜ì´ì§€ ì„¤ì •
# =========================
st.set_page_config(
    page_title="K-ë“œë¼ë§ˆ ë°ì´í„° ë¶„ì„ ë° ì˜ˆì¸¡",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# =========================
# 1. ë°ì´í„° ë¡œë“œ
# =========================
@st.cache_data
def load_data():
    raw = pd.read_json('drama_data.json')
    return pd.DataFrame({col: pd.Series(vals) for col, vals in raw.items()})

df = load_data()

mlb_cols = ['ì¥ë¥´','í”Œë«í¼','ë°©ì˜ìš”ì¼']
for col in mlb_cols:
    df[col] = df[col].apply(clean_cell)            # ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    mlb = MultiLabelBinarizer()
    arr = mlb.fit_transform(df[col])
    new_cols = [f"{col}_{c.upper()}" for c in mlb.classes_]
    df = pd.concat([df, pd.DataFrame(arr, columns=new_cols, index=df.index)], axis=1)
df.drop(columns=mlb_cols, inplace=True)

# =========================
# 2. ì „ì²˜ë¦¬ í•¨ìˆ˜
# =========================
def safe_eval(val):
    if isinstance(val, list):
        return val
    if pd.isna(val):
        return []
    if isinstance(val, str):
        try:
            parsed = ast.literal_eval(val)
            if isinstance(parsed, list):
                return parsed
        except:
            return []
    return []

def flatten_list_str(x):
    if isinstance(x, list):
        return ','.join([str(i).strip() for i in x])
    if isinstance(x, str):
        try:
            parsed = ast.literal_eval(x)
            if isinstance(parsed, list):
                return ','.join([str(i).strip() for i in parsed])
        except:
            return x
    try:
        if pd.isna(x):
            return ''
    except:
        pass
    return str(x)

def preprocess_ml_features(X):
    for col in ['ì¥ë¥´', 'í”Œë«í¼', 'ë°©ì˜ìš”ì¼']:
        if col in X.columns:
            X[col] = X[col].apply(safe_eval).apply(flatten_list_str)
    return X.fillna('')

# =========================
# 3. ë¦¬ìŠ¤íŠ¸í˜• ì»¬ëŸ¼ í’€ê¸° (EDA íƒ­ìš©)
# =========================
genres = df['ì¥ë¥´'].dropna().apply(safe_eval)
genre_list = [g for sub in genres for g in sub]

broadcasters = df['í”Œë«í¼'].dropna().apply(safe_eval)
broadcaster_list = [b for sub in broadcasters for b in sub]

weeks = df['ë°©ì˜ìš”ì¼'].dropna().apply(safe_eval)
week_list = [w for sub in weeks for w in sub]

# ê³ ìœ  ì¥ë¥´ ìˆ˜
unique_genres = set(genre_list)

# =========================
# 5. ì‚¬ì´ë“œë°”: ML íŒŒë¼ë¯¸í„° & ì˜ˆì¸¡ ì…ë ¥
# =========================
with st.sidebar:
    st.header("ğŸ¤– ëª¨ë¸ ì„¤ì •")
    model_type = st.selectbox('ëª¨ë¸ ì„ íƒ', ['Random Forest', 'Linear Regression'])
    test_size = st.slider('í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨', 0.1, 0.5, 0.2, 0.05)
    feature_cols = st.multiselect(
        'íŠ¹ì„± ì„ íƒ',
        ['ë‚˜ì´','ë°©ì˜ë…„ë„','ì„±ë³„','ì¥ë¥´','ë°°ìš°ëª…','í”Œë«í¼','ê²°í˜¼ì—¬ë¶€'],
        default=['ë‚˜ì´','ë°©ì˜ë…„ë„','ì¥ë¥´']
    )

    st.markdown("---")
    st.header("ğŸ¯ ì˜ˆìƒ í‰ì  ì˜ˆì¸¡")
    input_age     = st.number_input("ë°°ìš° ë‚˜ì´", 10, 80, 30)
    input_year    = st.number_input("ë°©ì˜ë…„ë„", 2000, 2025, 2021)
    input_gender  = st.selectbox("ì„±ë³„", sorted(df['ì„±ë³„'].dropna().unique()))
    genre_opts    = sorted(unique_genres)
    default_genre = [genre_opts[0]] if genre_opts else []
    input_genre   = st.multiselect("ì¥ë¥´", genre_opts, default=default_genre)
    platform_opts = sorted(set(broadcaster_list))
    default_plat  = [platform_opts[0]] if platform_opts else []
    input_plat    = st.multiselect("í”Œë«í¼", platform_opts, default=default_plat)
    input_married = st.selectbox("ê²°í˜¼ì—¬ë¶€", sorted(df['ê²°í˜¼ì—¬ë¶€'].dropna().unique()))
    predict_btn   = st.button("ì˜ˆì¸¡ ì‹¤í–‰")
    
# =========================
# 4. ë³¸ë¬¸: íƒ­ìœ¼ë¡œ EDA & ML
# =========================
st.title("K-ë“œë¼ë§ˆ ë°ì´í„° ë¶„ì„ ë° ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")

tab_labels = [
    "ğŸ—‚ ë°ì´í„° ê°œìš”",
    "ğŸ“Š ê¸°ì´ˆí†µê³„",
    "ğŸ“ˆ ë¶„í¬/êµì°¨ë¶„ì„",
    "ğŸ’¬ ì›Œë“œí´ë¼ìš°ë“œ",
    "âš™ï¸ ì‹¤ì‹œê°„ í•„í„°",
    "ğŸ” ìƒì„¸ ë¯¸ë¦¬ë³´ê¸°",
    "ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§",
    "ğŸ” GridSearchCV",
    "ğŸ¯ ì˜ˆìƒ í‰ì ì˜ˆì¸¡"
]
tabs = st.tabs(tab_labels)

# 4.1 ë°ì´í„° ê°œìš”
with tabs[0]:
    st.header("ë°ì´í„° ê°œìš”")
    col1, col2, col3 = st.columns(3)
    col1.metric("ì „ì²´ ìƒ˜í”Œ ìˆ˜", df.shape[0])
    col2.metric("ì „ì²´ ì»¬ëŸ¼ ìˆ˜", df.shape[1])
    col3.metric("ê³ ìœ  ì¥ë¥´ ìˆ˜", len(unique_genres))
    st.subheader("ê²°ì¸¡ì¹˜ ë¹„ìœ¨")
    st.write(df.isnull().mean())
    st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(), use_container_width=True)

# 4.2 ê¸°ì´ˆí†µê³„
with tabs[1]:
    st.header("ê¸°ì´ˆ í†µê³„")
    st.write(df['ì ìˆ˜'].astype(float).describe())
    fig, ax = plt.subplots(figsize=(6,3))
    ax.hist(df['ì ìˆ˜'].astype(float), bins=20)
    ax.set_title("ì ìˆ˜ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨")
    st.pyplot(fig, use_container_width=True)

# 4.3 ë¶„í¬/êµì°¨ë¶„ì„
import plotly.express as px

with tabs[2]:
    st.header("ë¶„í¬/êµì°¨ë¶„ì„")

    # 1) ë“œë¼ë§ˆ ì ìˆ˜ ë¶„í¬ & Top10 í‰ì  ì‘í’ˆ
    st.subheader("1) ë“œë¼ë§ˆ í‰ì  ë¶„í¬ & Top 10 í‰ì  ì‘í’ˆ")
    # (a) ë¶„í¬
    fig1 = px.histogram(
        df, x='ì ìˆ˜', nbins=20,
        title='ì „ì²´ ë“œë¼ë§ˆ í‰ì  ë¶„í¬',
        labels={'ì ìˆ˜':'í‰ì ','count':'ë¹ˆë„'}
    )
    st.plotly_chart(fig1, use_container_width=True)
    # (b) Top10
    top10 = df.nlargest(10, 'ì ìˆ˜')[['ë“œë¼ë§ˆëª…','ì ìˆ˜']].sort_values('ì ìˆ˜')
    top10_fig = px.bar(
        top10, x='ì ìˆ˜', y='ë“œë¼ë§ˆëª…', orientation='h', 
        text=top10['ì ìˆ˜'].map(lambda x: f"{x:.2f}"),
        title='Top 10 í‰ì  ì‘í’ˆ',
        labels={'ì ìˆ˜':'í‰ì ','ë“œë¼ë§ˆëª…':'ë“œë¼ë§ˆëª…'}
    )
    top10_fig.update_layout(yaxis={'categoryorder':'total ascending'})
    st.plotly_chart(top10_fig, use_container_width=True)

    # 2) ì—°ë„ë³„ í”Œë«í¼ë³„ ë“œë¼ë§ˆ ìˆ˜
    st.subheader("2) ì—°ë„ë³„ í”Œë«í¼ë³„ ë“œë¼ë§ˆ ìˆ˜")

    # ì›ë³¸ ì§‘ê³„
    ct = df.explode('í”Œë«í¼').groupby(['ë°©ì˜ë…„ë„','í”Œë«í¼']).size().reset_index(name='count')

    # ë³´ê³  ì‹¶ì€ í”Œë«í¼ ë¦¬ìŠ¤íŠ¸
    focus_plats = ['KBS', 'MBC', 'TVN', 'NETFLIX', 'JTBC']

    # ëŒ€ë¬¸ì/ì†Œë¬¸ì ì„ì—¬ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ëª¨ë‘ ëŒ€ë¬¸ìë¡œ ë§ì¶° í•„í„°
    ct['í”Œë«í¼_up'] = ct['í”Œë«í¼'].str.upper()
    ct_focused = ct[ct['í”Œë«í¼_up'].isin(focus_plats)].copy()
    
    # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    fig2 = px.line(
        ct_focused,
        x='ë°©ì˜ë…„ë„', y='count', color='í”Œë«í¼',
        title='ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ë³„ ë“œë¼ë§ˆ ìˆ˜',
        labels={'count':'ì‘í’ˆ ìˆ˜','ë°©ì˜ë…„ë„':'ë°©ì˜ë…„ë„'}
    )
    st.plotly_chart(fig2, use_container_width=True)

    # 3) ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸ ì¶œë ¥
    st.markdown("""
**ë„·í”Œë¦­ìŠ¤(OTT)ì˜ ê¸‰ì„±ì¥**  
ë„·í”Œë¦­ìŠ¤ëŠ” 2017ë…„ê¹Œì§€ëŠ” ì‚¬ì‹¤ìƒ ì˜í–¥ë ¥ì´ ê±°ì˜ ì—†ì—ˆìœ¼ë‚˜,  
2018ë…„ë¶€í„° ê¸‰ê²©í•˜ê²Œ ì‘í’ˆ ìˆ˜ê°€ ì¦ê°€í•˜ì—¬  
2020ë…„ì—ëŠ” ì „í†µ ë°©ì†¡ì‚¬ë“¤ê³¼ ì–´ê¹¨ë¥¼ ë‚˜ë€íˆ í•˜ê³ ,  
2021ë…„ì—ëŠ” ìµœìƒìœ„ê¶Œ(21í¸)ê¹Œì§€ ì¹˜ê³  ì˜¬ë¼ê°  
â†’ êµ­ë‚´ ë“œë¼ë§ˆ ì‚°ì—…ì˜ OTT ì¤‘ì‹¬ ì¬í¸ íë¦„ì´ ëª…í™•í•˜ê²Œ ë“œëŸ¬ë‚¨  

**ì§€ìƒíŒŒ(KBS, MBC)ì˜ ì§€ì†ì  ê°ì†Œ**  
KBS, MBC ë“± ì „í†µ 3ì‚¬ì˜ ë“œë¼ë§ˆ í¸ìˆ˜ëŠ” ë§¤ë…„ ê¾¸ì¤€íˆ ê°ì†Œ  
ì´ëŠ” OTT, ì¼€ì´ë¸”, ì‹ ìƒ í”Œë«í¼ê³¼ì˜ ê²½ìŸ ê²©í™”ì™€  
ì œì‘ ì˜ˆì‚°Â·ì‹œì²­ë¥  í•˜ë½ì˜ ì˜í–¥ìœ¼ë¡œ í’€ì´ë¨

**TVNì˜ ì„±ì¥ê³¼ ì •ì²´**  
tvN ì‘í’ˆ ì¤‘ ìƒë‹¹ìˆ˜ê°€ ë„·í”Œë¦­ìŠ¤ ë“± OTTì™€ ë™ì‹œë°©ì˜(ë©€í‹°í”Œë«í¼) ë˜ëŠ” êµ¬ì¡°  
â†’ ìì²´ ì±„ë„ ì„±ì¥ê³¼ ë™ì‹œì— OTT ì œíœ´ë¡œ ì‹œì²­ì ì ‘ì ì„ í™•ë³´

**2022ë…„ ì „ë°˜ì  ê°ì†Œ**  
2022ë…„ì—ëŠ” ëª¨ë“  í”Œë«í¼ì—ì„œ ì‘í’ˆ ìˆ˜ê°€ ì „ë…„ ëŒ€ë¹„ ê°ì†Œ  
ì´ëŠ” ì½”ë¡œë‚˜19 ë“± ì™¸ë¶€ ìš”ì¸ê³¼  
OTT-ë°©ì†¡ì‚¬ ë™ì‹œë°©ì˜ ë“± ì‹œì¥ ì¬í¸ì´ ë³µí•©ì ìœ¼ë¡œ ì‘ìš©í•œ ê²°ê³¼
""")


    # 3) ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ ë°°ìš° í‰ê·  í‰ì  ë¹„êµ
    st.subheader("3) ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ ë°°ìš° í‰ê·  í‰ì ")
    actor_genre_counts = df.explode('ì¥ë¥´').groupby('ë°°ìš°ëª…')['ì¥ë¥´'].nunique()
    multi = actor_genre_counts[actor_genre_counts>1].index
    df['ì¥ë¥´êµ¬ë¶„'] = df['ë°°ìš°ëª…'].apply(lambda x: 'ë©€í‹°ì¥ë¥´' if x in multi else 'ë‹¨ì¼ì¥ë¥´')
    grp = df.groupby('ì¥ë¥´êµ¬ë¶„')['ì ìˆ˜'].mean().reset_index()
    grp['ì ìˆ˜'] = grp['ì ìˆ˜'].round(2)
    fig3 = px.bar(
        grp, x='ì¥ë¥´êµ¬ë¶„', y='ì ìˆ˜', text='ì ìˆ˜',
        title='ë°°ìš° ì¥ë¥´êµ¬ë¶„ë³„ í‰ê·  í‰ì ',
        labels={'ì ìˆ˜':'í‰ê·  í‰ì ','ì¥ë¥´êµ¬ë¶„':'ë°°ìš°êµ¬ë¶„'}
    )
    fig3.update_yaxes(
    tickformat=".2f",   # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ ë ˆì´ë¸”
    dtick=0.5,          # 0.1 ë‹¨ìœ„ ëˆˆê¸ˆ
    showgrid=False,      # ê·¸ë¦¬ë“œ ì¼œê¸°
    gridcolor="LightGray",
    gridwidth=1
    )
    st.plotly_chart(fig3, use_container_width=True)

    # 4) ì‹ ì¸ vs ê²½ë ¥ ë°°ìš° í‰ê·  í‰ì  ë¹„êµ
    st.subheader("4) ì‹ ì¸(1-2ê°œ) vs ê²½ë ¥(3+ê°œ) ë°°ìš° í‰ê·  í‰ì ")
    actor_counts = df.groupby('ë°°ìš°ëª…').size()
    newbies = actor_counts[actor_counts<=2].index
    vets    = actor_counts[actor_counts>=3].index
    df['ê²½ë ¥êµ¬ë¶„'] = df['ë°°ìš°ëª…'].apply(
        lambda x: 'ì‹ ì¸(1-2ê°œ)' if x in newbies else ('ê²½ë ¥(3+ê°œ)' if x in vets else 'ê¸°íƒ€')
    )
    grp2 = (
        df[df['ê²½ë ¥êµ¬ë¶„']!='ê¸°íƒ€']
        .groupby('ê²½ë ¥êµ¬ë¶„')['ì ìˆ˜']
        .mean()
        .reset_index()
    )
    grp2['ì ìˆ˜'] = grp2['ì ìˆ˜'].round(2)
    fig4 = px.bar(
        grp2, x='ê²½ë ¥êµ¬ë¶„', y='ì ìˆ˜', text='ì ìˆ˜',
        title='ê²½ë ¥êµ¬ë¶„ë³„ í‰ê·  í‰ì ',
        labels={'ì ìˆ˜':'í‰ê·  í‰ì ','ê²½ë ¥êµ¬ë¶„':'ë°°ìš°êµ¬ë¶„'}
    )
    fig4.update_yaxes(
    tickformat=".2f",   # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ ë ˆì´ë¸”
    dtick=0.5,          # 0.1 ë‹¨ìœ„ ëˆˆê¸ˆ
    showgrid=False,      # ê·¸ë¦¬ë“œ ì¼œê¸°
    gridcolor="LightGray",
    gridwidth=1
    )
    st.plotly_chart(fig4, use_container_width=True)

    # 5) ì—°ë„ë³„ Top5 ì¥ë¥´ ë“œë¼ë§ˆ ìˆ˜ ë³€í™”
    st.subheader("5) ì—°ë„ë³„ Top5 ì¥ë¥´ ë“œë¼ë§ˆ ìˆ˜ ë³€í™”")
    top5 = pd.Series(genre_list).value_counts().head(5).index
    df_top5 = df.explode('ì¥ë¥´').query("ì¥ë¥´ in @top5")
    ct5 = df_top5.groupby(['ë°©ì˜ë…„ë„','ì¥ë¥´']).size().reset_index(name='count')
    fig5 = px.line(
        ct5, x='ë°©ì˜ë…„ë„', y='count', color='ì¥ë¥´',
        title='ì—°ë„ë³„ Top5 ì¥ë¥´ ì‘í’ˆ ìˆ˜ ë³€í™”',
        labels={'count':'ì‘í’ˆ ìˆ˜','ë°©ì˜ë…„ë„':'ë°©ì˜ë…„ë„'}
    )
    st.plotly_chart(fig5, use_container_width=True)

    # 6) ë°°ìš°ë³„ í‰ì  ë³€ë™ì„±(í‘œì¤€í¸ì°¨ ìƒìœ„ 10)
    st.subheader("6) ë°°ìš°ë³„ í‰ì  ë³€ë™ì„± (í‘œì¤€í¸ì°¨ ìƒìœ„ 10)")
    actor_std = (
        df.groupby('ë°°ìš°ëª…')['ì ìˆ˜']
        .std()
        .dropna()
        .nlargest(10)
        .reset_index(name='std')
    )
    actor_std['std'] = actor_std['std'].round(2)
    fig6 = px.bar(
        actor_std, x='ë°°ìš°ëª…', y='std', text='std',
        title='í‰ì  ë³€ë™ì„± ìƒìœ„ 10 ë°°ìš°',
        labels={'std':'í‘œì¤€í¸ì°¨','ë°°ìš°ëª…':'ë°°ìš°ëª…'}
    )
    fig6.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig6, use_container_width=True)

# 4.4 ì›Œë“œí´ë¼ìš°ë“œ
with tabs[3]:
    st.header("ì›Œë“œí´ë¼ìš°ë“œ")
    # ì¥ë¥´
    if genre_list:
        wc = WordCloud(width=800, height=400, background_color='white').generate(' '.join(genre_list))
        fig, ax = plt.subplots(figsize=(8,4))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig, use_container_width=True)
    else:
        st.info("ì¥ë¥´ ë°ì´í„° ë¶€ì¡±")

    # í”Œë«í¼
    if broadcaster_list:
        wc = WordCloud(width=800, height=400, background_color='white').generate(' '.join(broadcaster_list))
        fig, ax = plt.subplots(figsize=(8,4))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig, use_container_width=True)
    else:
        st.info("í”Œë«í¼ ë°ì´í„° ë¶€ì¡±")

    # ìš”ì¼
    if week_list:
        wc = WordCloud(width=800, height=400, background_color='white').generate(' '.join(week_list))
        fig, ax = plt.subplots(figsize=(8,4))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig, use_container_width=True)
    else:
        st.info("ìš”ì¼ ë°ì´í„° ë¶€ì¡±")

# 4.5 ì‹¤ì‹œê°„ í•„í„°
with tabs[4]:
    st.header("ì‹¤ì‹œê°„ í•„í„°")
    score_min, score_max = float(df['ì ìˆ˜'].min()), float(df['ì ìˆ˜'].max())
    score_slider = st.slider("ì ìˆ˜ ì´ìƒ", score_min, score_max, score_min)
    genre_opts = sorted(unique_genres)
    genre_select = st.multiselect("ì¥ë¥´ í•„í„°", genre_opts)
    year_min, year_max = int(df['ë°©ì˜ë…„ë„'].min()), int(df['ë°©ì˜ë…„ë„'].max())
    year_select = st.slider("ë°©ì˜ë…„ë„ ë²”ìœ„", year_min, year_max, (year_min, year_max))

    filtered = df[
        (df['ì ìˆ˜'].astype(float) >= score_slider) &
        df['ë°©ì˜ë…„ë„'].between(year_select[0], year_select[1])
    ]
    if genre_select:
        filtered = filtered[filtered['ì¥ë¥´'].apply(lambda x: any(g in x for g in genre_select))]
    st.dataframe(filtered.head(10), use_container_width=True)

# 4.6 ìƒì„¸ ë¯¸ë¦¬ë³´ê¸°
with tabs[5]:
    st.header("ìƒì„¸ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df, use_container_width=True)

# 4.7 ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§
with tabs[6]:
    st.header("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§")
    st.info("Random Forest / Linear Regression íšŒê·€ ì˜ˆì‹œ")
    # ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•œ feature_cols, model_type, test_size ì‚¬ìš©
    if len(feature_cols) > 0:
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import r2_score, mean_squared_error

        X = df[feature_cols].copy()
        y = df['ì ìˆ˜'].astype(float)
        X = preprocess_ml_features(X)
        X = pd.get_dummies(X, columns=[c for c in X.columns if X[c].dtype == 'object'])
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

        model = RandomForestRegressor(n_estimators=100, random_state=42) if model_type=="Random Forest" else LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        st.metric("RÂ² Score", f"{r2_score(y_test, y_pred):.3f}")
        st.metric("Test MSE", f"{mean_squared_error(y_test, y_pred):.3f}")
        st.subheader("ì‹¤ì œ vs ì˜ˆì¸¡ (ìƒìœ„ 5)")
        st.dataframe(pd.DataFrame({'ì‹¤ì œ': y_test, 'ì˜ˆì¸¡': y_pred}).head())
    else:
        st.warning("ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹ì„±ì„ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        
with tabs[7]:
    st.header("ğŸ”§ ëª¨ë¸ íŠœë‹ (GridSearchCV)")

    # 1) ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        label= "ëª¨ë¸ ì„ íƒ",
        options = [
            "KNN", "LinearRegression", "Ridge", "Lasso",
            "ElasticNet", "SGDRegressor", "SVR",
            "DecisionTree", "RandomForest", "XGBRegressor"
        ],
        key="tune_model"
    )

    # 2) ê³µí†µ íŒŒë¼ë¯¸í„° ì…ë ¥
    test_size    = st.slider("í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨", 0.1, 0.5, 0.2, 0.05, key="tune_ts")
    safe_feats   = [c for c in df.columns if c != "ì ìˆ˜"]
    feature_cols = st.multiselect("íŠœë‹í•  íŠ¹ì„± ì„ íƒ", safe_feats, key="tune_feats")

    if not feature_cols:
        st.warning("íŠ¹ì„±ì„ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
    else:
        # 3) ë°ì´í„° ë¶„í• 
        X = df[feature_cols]
        y = df["ì ìˆ˜"].astype(float)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )

        # 4) ì»¬ëŸ¼ ë¶„ë¥˜
        num_cols   = [c for c in feature_cols if X_train[c].dtype in ("int64","float64")]
        cat_single = [c for c in feature_cols
                        if X_train[c].dtype == "object"
                           and not isinstance(X_train[c].iloc[0], list)]
        cat_multi  = [c for c in feature_cols
                        if X_train[c].dtype == "object"
                           and isinstance(X_train[c].iloc[0], list)]

        # 5) ì „ì²˜ë¦¬ê¸°
        preprocessor = ColumnTransformer([
            ("num",    "passthrough",                           num_cols),
            ("onehot", OneHotEncoder(handle_unknown="ignore"), cat_single),
            ("mlb",    MultiLabelBinarizerTransformer(),        cat_multi),
        ], remainder="drop")

        # 6) ëª¨ë¸ ë§µí•‘
        from sklearn.neighbors     import KNeighborsRegressor
        from sklearn.linear_model  import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor
        from sklearn.svm           import SVR
        from sklearn.tree          import DecisionTreeRegressor
        from sklearn.ensemble      import RandomForestRegressor
        from xgboost               import XGBRegressor

        model_map = {
            "KNN":              KNeighborsRegressor(),
            "LinearRegression": LinearRegression(),
            "Ridge":            Ridge(),
            "Lasso":            Lasso(),
            "ElasticNet":       ElasticNet(),
            "SGDRegressor":     SGDRegressor(max_iter=1000, tol=1e-3),
            "SVR":              SVR(),
            "DecisionTree":     DecisionTreeRegressor(random_state=42),
            "RandomForest":     RandomForestRegressor(random_state=42),
            "XGBRegressor":     XGBRegressor(random_state=42, use_label_encoder=False, eval_metric="rmse")
        }
        model = model_map[model_name]

        # 7) íŒŒì´í”„ë¼ì¸
        steps = [("pre", preprocessor)]
        if model_name == "KNN":
            steps += [
                ("poly",  PolynomialFeatures(include_bias=False)),
                ("scale", StandardScaler())
            ]
        steps.append(("model", model))
        pipe = Pipeline(steps)

        # 8) í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ
        grids = {
            "KNN":            {"poly__degree":[1,2,3], "model__n_neighbors":list(range(3,11))},
            "LinearRegression":{},
            "Ridge":          {"model__alpha":[0.1,1.0,10.0]},
            "Lasso":          {"model__alpha":[0.001,0.01,0.1,1.0]},
            "ElasticNet":     {"model__alpha":[0.01,0.1,1.0], "model__l1_ratio":[0.2,0.5,0.8]},
            "SGDRegressor":   {"model__alpha":[1e-4,1e-3,1e-2], "model__penalty":["l2","l1","elasticnet"]},
            "SVR":            {"model__C":[0.1,1,10], "model__gamma":["scale","auto"]},
            "DecisionTree":   {"model__max_depth":[None,5,10,20]},
            "RandomForest":   {"model__n_estimators":[50,100,200], "model__max_depth":[None,5,10]},
            "XGBRegressor":   {"model__n_estimators":[50,100,200], "model__max_depth":[3,6,9]}
        }
        param_grid = grids[model_name]

        # 9) GridSearchCV
        with st.spinner("GridSearchCV ì‹¤í–‰ ì¤‘â€¦"):
            gs = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1,
                              scoring="r2", error_score="raise")
            gs.fit(X_train, y_train)

        # 10) ì¶œë ¥
        st.subheader("ìµœì  íŒŒë¼ë¯¸í„°")
        st.json(gs.best_params_)
        st.metric("Best CV RÂ²", f"{gs.best_score_:.3f}")

        y_pred = gs.predict(X_test)
        st.subheader("í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥")
        st.metric("Test RÂ²",   f"{r2_score(y_test, y_pred):.3f}")
        st.metric("Test RMSE", f"{mean_squared_error(y_test, y_pred, squared=False):.3f}")


with tabs[8]:
    st.header("ğŸ¯ ì˜ˆìƒ í‰ì ì˜ˆì¸¡")

    st.subheader("1) ëª¨ë¸ ì„¤ì •")
    model_type  = st.selectbox('ëª¨ë¸ ì„ íƒ', ['Random Forest', 'Linear Regression'])
    test_size   = st.slider('í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨', 0.1, 0.5, 0.2, 0.05)
    feature_cols = st.multiselect(
        'íŠ¹ì„± ì„ íƒ',
        ['ë‚˜ì´','ë°©ì˜ë…„ë„','ì„±ë³„','ì¥ë¥´','ë°°ìš°ëª…','í”Œë«í¼','ê²°í˜¼ì—¬ë¶€'],
        default=['ë‚˜ì´','ë°©ì˜ë…„ë„','ì¥ë¥´']
    )

    st.markdown("---")
    st.subheader("2) ì˜ˆì¸¡ ì…ë ¥")
    input_age     = st.number_input("ë°°ìš° ë‚˜ì´", 10, 80, 30)
    input_year    = st.number_input("ë°©ì˜ë…„ë„", 2000, 2025, 2021)
    input_gender  = st.selectbox("ì„±ë³„", sorted(df['ì„±ë³„'].dropna().unique()))

    genre_opts    = sorted(unique_genres)
    default_genre = [genre_opts[0]] if genre_opts else []
    input_genre   = st.multiselect("ì¥ë¥´", genre_opts, default=default_genre)

    platform_opts = sorted(set(broadcaster_list))
    default_plat  = [platform_opts[0]] if platform_opts else []
    input_plat    = st.multiselect("í”Œë«í¼", platform_opts, default=default_plat)

    input_married = st.selectbox("ê²°í˜¼ì—¬ë¶€", sorted(df['ê²°í˜¼ì—¬ë¶€'].dropna().unique()))

    predict_btn   = st.button("ì˜ˆì¸¡ ì‹¤í–‰")

    if predict_btn:
        # --- 1. í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬ ---
        X_all = df[feature_cols].copy()
        y_all = df['ì ìˆ˜'].astype(float)
        X_all = preprocess_ml_features(X_all)
        X_all = pd.get_dummies(X_all, columns=[c for c in X_all.columns if X_all[c].dtype=='object'])

        # --- 2. ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ ---
        user_df = pd.DataFrame([{
            'ë‚˜ì´': input_age,
            'ë°©ì˜ë…„ë„': input_year,
            'ì„±ë³„': input_gender,
            'ì¥ë¥´': input_genre,
            'ë°°ìš°ëª…': df['ë°°ìš°ëª…'].dropna().iloc[0],  # í•„ìš”ì‹œ selectboxë¡œ ë³€ê²½
            'í”Œë«í¼': input_plat,
            'ê²°í˜¼ì—¬ë¶€': input_married
        }])
        u = preprocess_ml_features(user_df)
        u = pd.get_dummies(u, columns=[c for c in u.columns if u[c].dtype=='object'])
        for c in X_all.columns:
            if c not in u.columns:
                u[c] = 0
        u = u[X_all.columns]

        # --- 3. ëª¨ë¸ í•™ìŠµ & ì˜ˆì¸¡ ---
        model = RandomForestRegressor(n_estimators=100, random_state=42) \
                if model_type=="Random Forest" else LinearRegression()
        model.fit(X_all, y_all)
        pred = model.predict(u)[0]

        st.success(f"ğŸ’¡ ì˜ˆìƒ í‰ì : {pred:.2f}")


# =========================
# 6. ì˜ˆì¸¡ ì‹¤í–‰
# =========================
if predict_btn:
    user_input = pd.DataFrame([{
        'ë‚˜ì´': input_age,
        'ë°©ì˜ë…„ë„': input_year,
        'ì„±ë³„': input_gender,
        'ì¥ë¥´': input_genre,
        'ë°°ìš°ëª…': st.selectbox("ë°°ìš°ëª…", sorted(df['ë°°ìš°ëª…'].dropna().unique())),  # ëª¨ë¸ë§ íƒ­ê³¼ ë™ì¼í•˜ê²Œ
        'í”Œë«í¼': input_plat,
        'ê²°í˜¼ì—¬ë¶€': input_married
    }])

    # ì „ì²˜ë¦¬ & ì¸ì½”ë”©
    X_all = df[feature_cols].copy()
    y_all = df['ì ìˆ˜'].astype(float)
    X_all = preprocess_ml_features(X_all)
    X_all = pd.get_dummies(X_all, columns=[c for c in X_all.columns if X_all[c].dtype == 'object'])

    user_proc = preprocess_ml_features(user_input)
    user_proc = pd.get_dummies(user_proc, columns=[c for c in user_proc.columns if user_proc[c].dtype == 'object'])
    for col in X_all.columns:
        if col not in user_proc.columns:
            user_proc[col] = 0
    user_proc = user_proc[X_all.columns]

    # ëª¨ë¸ í•™ìŠµ & ì˜ˆì¸¡
    model = RandomForestRegressor(n_estimators=100, random_state=42) if model_type=="Random Forest" else LinearRegression()
    model.fit(X_all, y_all)
    prediction = model.predict(user_proc)[0]

    st.success(f"ğŸ’¡ ì˜ˆìƒ í‰ì : {prediction:.2f}")
