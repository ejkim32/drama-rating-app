# app.py
import os
import ast
import random
import numpy as np
import pandas as pd
from pathlib import Path
import platform

import streamlit as st
import plotly.express as px

# ===== í˜ì´ì§€ ì„¤ì •(ê°€ì¥ ì²˜ìŒ st.* í˜¸ì¶œ) =====
st.set_page_config(page_title="K-ë“œë¼ë§ˆ ë¶„ì„/ì˜ˆì¸¡", page_icon="ğŸ¬", layout="wide")

# ===== ì „ì—­: ì‹œë“œ ê³ ì •(ì¬í˜„ì„±) =====
SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED)
np.random.seed(SEED)

# ===== ì „ì—­: Matplotlib/WordCloud í•œê¸€ í°íŠ¸ ë¶€íŠ¸ìŠ¤íŠ¸ë© =====
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# ìºì‹œëŠ” í•œ ë²ˆë§Œ ì‚­ì œ(ìƒˆ í°íŠ¸ ì¸ì‹)
if st.session_state.get("font_cache_cleared") is not True:
    import shutil
    shutil.rmtree(matplotlib.get_cachedir(), ignore_errors=True)
    st.session_state["font_cache_cleared"] = True

def ensure_korean_font():
    """Matplotlib + WordCloudìš© í•œê¸€ í°íŠ¸ ì„¸íŒ… (ë¡œì»¬/í´ë¼ìš°ë“œ/Windows ëª¨ë‘ ì•ˆì „)"""
    matplotlib.rcParams['axes.unicode_minus'] = False
    base = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()

    candidates = [
        base / "fonts" / "NanumGothic.ttf",
        base / "fonts" / "NanumGothic-Regular.ttf",
    ]
    if platform.system() == "Windows":
        candidates += [
            Path(r"C:\Windows\Fonts\malgun.ttf"),
            Path(r"C:\Windows\Fonts\malgunbd.ttf"),
        ]
    wanted = ("nanum","malgun","applegothic","notosanscjk","sourcehan","gulim","dotum","batang","pretendard","gowun","spoqa")
    for f in fm.findSystemFonts(fontext="ttf"):
        if any(k in os.path.basename(f).lower() for k in wanted):
            candidates.append(Path(f))

    for p in candidates:
        try:
            if p.exists():
                fm.fontManager.addfont(str(p))
                family = fm.FontProperties(fname=str(p)).get_name()
                matplotlib.rcParams['font.family'] = family
                st.session_state["kfont_path"] = str(p)  # WordCloudì—ì„œ ì‚¬ìš©
                return family
        except Exception:
            continue
    st.session_state["kfont_path"] = None
    return None

_ = ensure_korean_font()

# ===== Colabê³¼ ë™ì¼í•œ ë©€í‹°ë¼ë²¨ ì „ì²˜ë¦¬ =====
from sklearn.preprocessing import MultiLabelBinarizer

def clean_cell_colab(x):
    if isinstance(x, list):
        return [str(i).strip() for i in x if pd.notna(i)]
    if pd.isna(x):
        return []
    if isinstance(x, str):
        try:
            parsed = ast.literal_eval(x)
            if isinstance(parsed, list):
                return [str(i).strip() for i in parsed if pd.notna(i)]
            return [x.strip()]
        except Exception:
            return [x.strip()]
    return [str(x).strip()]

def colab_multilabel_fit_transform(df: pd.DataFrame, cols=('ì¥ë¥´','ë°©ì˜ìš”ì¼','í”Œë«í¼')) -> pd.DataFrame:
    out = df.copy()
    for col in cols:
        out[col] = out[col].apply(clean_cell_colab)
        mlb = MultiLabelBinarizer()
        arr = mlb.fit_transform(out[col])
        new_cols = [f"{col}_{c.strip().upper()}" for c in mlb.classes_]
        out = out.drop(columns=[c for c in new_cols if c in out.columns], errors='ignore')
        out = pd.concat([out, pd.DataFrame(arr, columns=new_cols, index=out.index)], axis=1)
        st.session_state[f"mlb_classes_{col}"] = mlb.classes_.tolist()
    return out

def colab_multilabel_transform(df: pd.DataFrame, cols=('ì¥ë¥´','ë°©ì˜ìš”ì¼','í”Œë«í¼')) -> pd.DataFrame:
    out = df.copy()
    for col in cols:
        out[col] = out[col].apply(clean_cell_colab)
        classes = st.session_state.get(f"mlb_classes_{col}", [])
        mlb = MultiLabelBinarizer(classes=classes)
        arr = mlb.transform(out[col])
        new_cols = [f"{col}_{c.strip().upper()}" for c in mlb.classes_]
        out = out.drop(columns=[c for c in new_cols if c in out.columns], errors='ignore')
        out = pd.concat([out, pd.DataFrame(arr, columns=new_cols, index=out.index)], axis=1)
    return out

def expand_feature_cols_for_training(base: pd.DataFrame, selected: list):
    cols = []
    for c in selected:
        if c in ('ì¥ë¥´','ë°©ì˜ìš”ì¼','í”Œë«í¼'):
            prefix = f"{c}_"
            cols += [k for k in base.columns if k.startswith(prefix)]
        else:
            cols.append(c)
    return cols

def build_X_from_selected(base: pd.DataFrame, selected: list) -> pd.DataFrame:
    X = pd.DataFrame(index=base.index)
    use_cols = expand_feature_cols_for_training(base, selected)
    if use_cols:
        X = pd.concat([X, base[use_cols]], axis=1)

    # ë‹¨ì¼ ë²”ì£¼í˜•(ì„±ë³„/ê²°í˜¼ì—¬ë¶€/ë°°ìš°ëª… ë“±) ì›í•«
    singles = [c for c in selected if c not in ('ì¥ë¥´','ë°©ì˜ìš”ì¼','í”Œë«í¼')]
    for c in singles:
        if c in base.columns and base[c].dtype == 'object':
            d = pd.get_dummies(base[c], prefix=c)
            X = pd.concat([X, d], axis=1)
        elif c in base.columns:
            X[c] = base[c]
    return X

# ===== ë°ì´í„° ë¡œë“œ =====
@st.cache_data
def load_data():
    raw = pd.read_json('drama_data.json')
    return pd.DataFrame({c: pd.Series(v) for c,v in raw.items()})

raw_df = load_data()

# Colabê³¼ ë™ì¼ ì¸ì½”ë”© ê²°ê³¼(ëª¨ë¸ìš© DF)
df_mlb = colab_multilabel_fit_transform(raw_df, cols=('ì¥ë¥´','ë°©ì˜ìš”ì¼','í”Œë«í¼'))
df_mlb['ì ìˆ˜'] = pd.to_numeric(df_mlb['ì ìˆ˜'], errors='coerce')
y_all = df_mlb['ì ìˆ˜']

# ===== EDAìš© ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„ =====
genre_list = [g for sub in raw_df['ì¥ë¥´'].dropna().apply(clean_cell_colab) for g in sub]
broadcaster_list = [b for sub in raw_df['í”Œë«í¼'].dropna().apply(clean_cell_colab) for b in sub]
week_list = [w for sub in raw_df['ë°©ì˜ìš”ì¼'].dropna().apply(clean_cell_colab) for w in sub]
unique_genres = sorted(set(genre_list))

# ===== ì‚¬ì´ë“œë°” =====
with st.sidebar:
    st.header("ğŸ¤– ëª¨ë¸ ì„¤ì •")
    model_type   = st.selectbox('ëª¨ë¸ ì„ íƒ', ['Random Forest','Linear Regression'])
    test_size    = st.slider('í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨', 0.1, 0.5, 0.2, 0.05)
    feature_cols = st.multiselect(
        'íŠ¹ì„± ì„ íƒ',
        ['ë‚˜ì´','ë°©ì˜ë…„ë„','ì„±ë³„','ì¥ë¥´','ë°°ìš°ëª…','í”Œë«í¼','ê²°í˜¼ì—¬ë¶€'],
        default=['ë‚˜ì´','ë°©ì˜ë…„ë„','ì¥ë¥´']
    )

# ===== íƒ­ êµ¬ì„± =====
tabs = st.tabs(["ğŸ—‚ê°œìš”","ğŸ“Šê¸°ì´ˆí†µê³„","ğŸ“ˆë¶„í¬/êµì°¨","ğŸ’¬ì›Œë“œí´ë¼ìš°ë“œ","âš™ï¸í•„í„°","ğŸ”ì „ì²´ë³´ê¸°","ğŸ¤–MLëª¨ë¸","ğŸ”§íŠœë‹","ğŸ¯ì˜ˆì¸¡"])

# --- 4.1 ë°ì´í„° ê°œìš” ---
with tabs[0]:
    st.header("ë°ì´í„° ê°œìš”")
    c1,c2,c3 = st.columns(3)
    c1.metric("ìƒ˜í”Œ ìˆ˜", raw_df.shape[0])
    c2.metric("ì»¬ëŸ¼ ìˆ˜", raw_df.shape[1])
    c3.metric("ê³ ìœ  ì¥ë¥´", len(unique_genres))
    st.subheader("ê²°ì¸¡ì¹˜ ë¹„ìœ¨")
    st.dataframe(raw_df.isnull().mean())
    st.subheader("ì›ë³¸ ìƒ˜í”Œ")
    st.dataframe(raw_df.head(), use_container_width=True)

# --- 4.2 ê¸°ì´ˆí†µê³„ ---
with tabs[1]:
    st.header("ê¸°ì´ˆ í†µê³„: ì ìˆ˜")
    st.write(raw_df['ì ìˆ˜'].astype(float).describe())
    fig,ax=plt.subplots(figsize=(6,3))
    ax.hist(raw_df['ì ìˆ˜'].astype(float), bins=20)
    ax.set_title("íˆìŠ¤í† ê·¸ë¨")
    st.pyplot(fig)

# --- 4.3 ë¶„í¬/êµì°¨ë¶„ì„ ---
with tabs[2]:
    st.header("ë¶„í¬ ë° êµì°¨ë¶„ì„")

    # 1) ì „ì²´ í‰ì  ë¶„í¬
    st.subheader("ì „ì²´ í‰ì  ë¶„í¬")
    fig1 = px.histogram(raw_df, x='ì ìˆ˜', nbins=20, title="ì „ì²´ í‰ì  ë¶„í¬")
    st.plotly_chart(fig1, use_container_width=True)

    # 2) Top 10 í‰ì  ì‘í’ˆ
    st.subheader("Top 10 í‰ì  ì‘í’ˆ")
    top10 = raw_df.nlargest(10, 'ì ìˆ˜')[['ë“œë¼ë§ˆëª…','ì ìˆ˜']].sort_values('ì ìˆ˜')
    fig2 = px.bar(top10, x='ì ìˆ˜', y='ë“œë¼ë§ˆëª…', orientation='h', text='ì ìˆ˜', title="Top 10 í‰ì  ì‘í’ˆ")
    st.plotly_chart(fig2, use_container_width=True)

    # 3) ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
    st.subheader("ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜")
    ct = (
        pd.DataFrame({
            'ë°©ì˜ë…„ë„': raw_df['ë°©ì˜ë…„ë„'],
            'í”Œë«í¼': raw_df['í”Œë«í¼'].apply(clean_cell_colab)
        })
        .explode('í”Œë«í¼')
        .groupby(['ë°©ì˜ë…„ë„', 'í”Œë«í¼']).size().reset_index(name='count')
    )
    ct['í”Œë«í¼_up'] = ct['í”Œë«í¼'].str.upper()
    focus = ['KBS','MBC','TVN','NETFLIX','SBS']
    fig3 = px.line(
        ct[ct['í”Œë«í¼_up'].isin(focus)],
        x='ë°©ì˜ë…„ë„', y='count', color='í”Œë«í¼',
        log_y=True, title="ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)"
    )
    st.plotly_chart(fig3, use_container_width=True)

    # 4) ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ (ë°°ìš° ë‹¨ìœ„ ë°•ìŠ¤í”Œë¡¯)
    st.subheader("ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ í‰ê·  í‰ì  (ë°°ìš° ë‹¨ìœ„ ë°•ìŠ¤í”Œë¡¯)")
    ag = (
        pd.DataFrame({'ë°°ìš°ëª…': raw_df['ë°°ìš°ëª…'], 'ì¥ë¥´': raw_df['ì¥ë¥´'].apply(clean_cell_colab)})
        .explode('ì¥ë¥´')
        .groupby('ë°°ìš°ëª…')['ì¥ë¥´'].nunique()
    )
    multi_set = set(ag[ag > 1].index)
    label_map = {name: ('ë©€í‹°ì¥ë¥´' if name in multi_set else 'ë‹¨ì¼ì¥ë¥´') for name in ag.index}
    actor_mean = (
        raw_df.groupby('ë°°ìš°ëª…', as_index=False)['ì ìˆ˜'].mean()
              .rename(columns={'ì ìˆ˜': 'ë°°ìš°í‰ê· ì ìˆ˜'})
    )
    actor_mean['ì¥ë¥´êµ¬ë¶„'] = actor_mean['ë°°ìš°ëª…'].map(label_map)
    fig_box = px.box(
        actor_mean, x='ì¥ë¥´êµ¬ë¶„', y='ë°°ìš°í‰ê· ì ìˆ˜',
        title="ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ ë°°ìš° ë‹¨ìœ„ í‰ê·  ì ìˆ˜ ë¶„í¬"
    )
    st.plotly_chart(fig_box, use_container_width=True)

    # 5) ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ
    st.subheader("ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ")
    main_roles = raw_df[raw_df['ì—­í• '] == 'ì£¼ì—°'].copy()
    main_roles['ê²°í˜¼ìƒíƒœ'] = main_roles['ê²°í˜¼ì—¬ë¶€'].apply(lambda x: 'ë¯¸í˜¼' if x == 'ë¯¸í˜¼' else 'ë¯¸í˜¼ ì™¸')
    avg_scores_by_marriage = main_roles.groupby('ê²°í˜¼ìƒíƒœ')['ì ìˆ˜'].mean()

    fig, ax = plt.subplots(figsize=(6, 5))
    bars = ax.bar(avg_scores_by_marriage.index, avg_scores_by_marriage.values, color=['mediumseagreen', 'gray'])
    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f'{yval:.3f}',
                ha='center', va='bottom', fontsize=12, fontweight='bold')
    ax.set_title('ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ', fontsize=14)
    ax.set_ylabel('í‰ê·  ì ìˆ˜'); ax.set_xlabel('ê²°í˜¼ ìƒíƒœ')
    ax.set_ylim(min(avg_scores_by_marriage.values) - 0.05, max(avg_scores_by_marriage.values) + 0.05)
    ax.grid(axis='y', linestyle='--', alpha=0.5)
    st.pyplot(fig)

    # 6) ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ & í‰ê·  ì ìˆ˜ (ë§‰ëŒ€+ì„ )
    st.subheader("ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜")
    df_exploded = raw_df.copy()
    df_exploded['ì¥ë¥´'] = df_exploded['ì¥ë¥´'].apply(clean_cell_colab)
    df_exploded = df_exploded.explode('ì¥ë¥´').dropna(subset=['ì¥ë¥´','ì ìˆ˜'])
    genre_score = df_exploded.groupby('ì¥ë¥´')['ì ìˆ˜'].mean().round(3)
    genre_count = df_exploded['ì¥ë¥´'].value_counts()
    genre_df = (pd.DataFrame({'í‰ê·  ì ìˆ˜': genre_score, 'ì‘í’ˆ ìˆ˜': genre_count})
                .reset_index().rename(columns={'index': 'ì¥ë¥´'}))
    genre_df = genre_df.sort_values('ì‘í’ˆ ìˆ˜', ascending=False).reset_index(drop=True)

    fig, ax1 = plt.subplots(figsize=(12, 6))
    bars = ax1.bar(range(len(genre_df)), genre_df['ì‘í’ˆ ìˆ˜'], color='lightgray')
    ax1.set_ylabel('ì‘í’ˆ ìˆ˜', fontsize=12)
    ax1.set_xticks(range(len(genre_df)))
    ax1.set_xticklabels(genre_df['ì¥ë¥´'], rotation=45, ha='right')
    for i, rect in enumerate(bars):
        h = rect.get_height()
        ax1.text(i, h + max(2, h*0.01), f'{int(h)}', ha='center', va='bottom', fontsize=10, fontweight='bold', color='#444')

    ax2 = ax1.twinx()
    ax2.plot(range(len(genre_df)), genre_df['í‰ê·  ì ìˆ˜'], marker='o', linewidth=2, color='tab:blue')
    ax2.set_ylabel('í‰ê·  ì ìˆ˜', fontsize=12, color='tab:blue')
    ax2.tick_params(axis='y', colors='tab:blue')
    ax2.set_ylim(genre_df['í‰ê·  ì ìˆ˜'].min() - 0.1, genre_df['í‰ê·  ì ìˆ˜'].max() + 0.1)
    for i, v in enumerate(genre_df['í‰ê·  ì ìˆ˜']):
        ax2.text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold', color='tab:blue')
    plt.title('ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜', fontsize=14)
    ax1.set_xlabel('ì¥ë¥´', fontsize=12)
    ax1.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()
    st.pyplot(fig)

    # 7) ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ & í‰ê·  ì ìˆ˜
    st.subheader("ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜ (ì›”â†’ì¼)")
    dfe = raw_df.copy()
    dfe['ë°©ì˜ìš”ì¼'] = dfe['ë°©ì˜ìš”ì¼'].apply(clean_cell_colab)
    dfe = dfe.explode('ë°©ì˜ìš”ì¼').dropna(subset=['ë°©ì˜ìš”ì¼','ì ìˆ˜']).copy()
    dfe['ë°©ì˜ìš”ì¼'] = dfe['ë°©ì˜ìš”ì¼'].astype(str).str.strip().str.lower()

    ordered_days_en = ['monday','tuesday','wednesday','thursday','friday','saturday','sunday']
    day_label_ko = {'monday':'ì›”','tuesday':'í™”','wednesday':'ìˆ˜','thursday':'ëª©','friday':'ê¸ˆ','saturday':'í† ','sunday':'ì¼'}

    mean_score_by_day = dfe.groupby('ë°©ì˜ìš”ì¼')['ì ìˆ˜'].mean().reindex(ordered_days_en)
    count_by_day = dfe['ë°©ì˜ìš”ì¼'].value_counts().reindex(ordered_days_en).fillna(0).astype(int)

    fig, ax1 = plt.subplots(figsize=(10, 6))
    bars = ax1.bar(ordered_days_en, count_by_day.values, alpha=0.3, color='tab:gray')
    ax1.set_ylabel('ì‘í’ˆ ìˆ˜', color='tab:gray', fontsize=12)
    ax1.tick_params(axis='y', labelcolor='tab:gray')
    for bar in bars:
        h = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2, h + 0.5, f'{int(h)}', ha='center', va='bottom', fontsize=9, color='black')

    ax2 = ax1.twinx()
    ax2.plot(ordered_days_en, mean_score_by_day.values, marker='o', color='tab:blue')
    ax2.set_ylabel('í‰ê·  ì ìˆ˜', color='tab:blue', fontsize=12)
    ax2.tick_params(axis='y', labelcolor='tab:blue')
    if mean_score_by_day.notna().any():
        ax2.set_ylim(mean_score_by_day.min() - 0.05, mean_score_by_day.max() + 0.05)
    for x, y in zip(ordered_days_en, mean_score_by_day.values):
        if pd.notna(y):
            ax2.text(x, y + 0.005, f'{y:.3f}', color='tab:blue', fontsize=9, ha='center')

    ax1.set_xticks(ordered_days_en)
    ax1.set_xticklabels([day_label_ko[d] for d in ordered_days_en])
    plt.title('ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜ (ì›”ìš”ì¼ â†’ ì¼ìš”ì¼ ìˆœ)', fontsize=14)
    plt.tight_layout()
    st.pyplot(fig)

# --- 4.4 ì›Œë“œí´ë¼ìš°ë“œ ---
from wordcloud import WordCloud
with tabs[3]:
    st.header("ì›Œë“œí´ë¼ìš°ë“œ")
    font_path = st.session_state.get("kfont_path")
    if genre_list:
        wc = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate(' '.join(genre_list))
        fig,ax=plt.subplots(); ax.imshow(wc, interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
    if broadcaster_list:
        wc = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate(' '.join(broadcaster_list))
        fig,ax=plt.subplots(); ax.imshow(wc, interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
    if week_list:
        wc = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate(' '.join(week_list))
        fig,ax=plt.subplots(); ax.imshow(wc, interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)

# --- 4.5 ì‹¤ì‹œê°„ í•„í„° ---
with tabs[4]:
    st.header("ì‹¤ì‹œê°„ í•„í„°")
    smin,smax = float(raw_df['ì ìˆ˜'].min()), float(raw_df['ì ìˆ˜'].max())
    sfilter = st.slider("ìµœì†Œ í‰ì ", smin,smax,smin)
    yfilter = st.slider("ë°©ì˜ë…„ë„ ë²”ìœ„", int(raw_df['ë°©ì˜ë…„ë„'].min()), int(raw_df['ë°©ì˜ë…„ë„'].max()), (2000,2025))
    filt = raw_df[(raw_df['ì ìˆ˜']>=sfilter) & raw_df['ë°©ì˜ë…„ë„'].between(*yfilter)]
    st.dataframe(filt.head(20))

# --- 4.6 ì „ì²´ ë¯¸ë¦¬ë³´ê¸° ---
with tabs[5]:
    st.header("ì›ë³¸ ì „ì²´ë³´ê¸°")
    st.dataframe(raw_df, use_container_width=True)

# --- 4.7 ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ ---
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

with tabs[6]:
    st.header("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§")
    if feature_cols:
        X_all = build_X_from_selected(df_mlb, feature_cols)

        # splitì„ ì„¸ì…˜ì— ê³ ì • (ì¬ì‹¤í–‰ì—ë„ ìœ ì§€)
        key = ("split", tuple(X_all.columns), float(test_size))
        if st.session_state.get("split_key") != key:
            X_train, X_test, y_train, y_test = train_test_split(
                X_all, y_all, test_size=test_size, random_state=SEED, shuffle=True
            )
            st.session_state["split"] = (X_train, X_test, y_train, y_test)
            st.session_state["split_key"] = key
        else:
            X_train, X_test, y_train, y_test = st.session_state["split"]

        model = RandomForestRegressor(random_state=SEED) if model_type=="Random Forest" else LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        st.metric("RÂ²", f"{r2_score(y_test,y_pred):.3f}")
        st.metric("MSE", f"{mean_squared_error(y_test,y_pred):.3f}")
    else:
        st.warning("ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”.")

# --- 4.8 GridSearch íŠœë‹ ---
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet, SGDRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

with tabs[7]:
    st.header("GridSearchCV íŠœë‹")
    if "split" not in st.session_state:
        st.info("ë¨¼ì € 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§' íƒ­ì—ì„œ í•™ìŠµ/ìŠ¤í”Œë¦¿ì„ ìƒì„±í•˜ì„¸ìš”.")
    else:
        X_train, X_test, y_train, y_test = st.session_state["split"]
        scoring = st.selectbox("ìŠ¤ì½”ì–´ë§", ["neg_mean_squared_error", "r2"], index=0)
        cv = st.number_input("CV í´ë“œ ìˆ˜", min_value=3, max_value=10, value=5, step=1)

        model_zoo = {
            "KNN": KNeighborsRegressor(),
            "Linear Regression": LinearRegression(),
            "Ridge": Ridge(),
            "Lasso": Lasso(),
            "ElasticNet": ElasticNet(max_iter=10000),
            "SGDRegressor": SGDRegressor(max_iter=10000),
            "SVR": SVR(),
            "Decision Tree": DecisionTreeRegressor(random_state=SEED),
            "Random Forest": RandomForestRegressor(random_state=SEED),
        }

        def make_pipeline(name):
            if name in ["Decision Tree", "Random Forest"]:
                return Pipeline([("model", model_zoo[name])])
            else:
                return Pipeline([
                    ("poly", PolynomialFeatures(include_bias=False)),
                    ("scaler", StandardScaler()),
                    ("model", model_zoo[name]),
                ])

        param_grids = {
            "KNN": {"poly__degree": [1, 2, 3], "model__n_neighbors": [3,4,5,6,7,8,9,10]},
            "Linear Regression": {"poly__degree": [1, 2, 3]},
            "Ridge": {"poly__degree": [1, 2, 3], "model__alpha": [0.001, 0.01, 0.1, 1, 10, 100, 1000]},
            "Lasso": {"poly__degree": [1, 2, 3], "model__alpha": [0.001, 0.01, 0.1, 1, 10, 100, 1000]},
            "ElasticNet": {"poly__degree": [1, 2, 3], "model__alpha": [0.001, 0.01, 0.1, 1, 10, 100, 1000], "model__l1_ratio": [0.1, 0.5, 0.9]},
            "SGDRegressor": {"poly__degree": [1, 2, 3], "model__learning_rate": ["constant", "invscaling", "adaptive"]},
            "SVR": {"poly__degree": [1, 2, 3], "model__kernel": ["poly", "rbf", "sigmoid"], "model__degree": [1, 2, 3]},
            "Decision Tree": {"model__max_depth": [10, 15, 20, 25, 30], "model__min_samples_split": [5, 6, 7, 8, 9, 10], "model__min_samples_leaf": [2, 3, 4, 5], "model__max_leaf_nodes": [None, 10, 20, 30]},
            "Random Forest": {"model__n_estimators": [100, 200, 300], "model__min_samples_split": [5, 6, 7, 8, 9, 10], "model__max_depth": [5, 10, 15, 20, 25, 30]},
        }

        model_name = st.selectbox("íŠœë‹í•  ëª¨ë¸ ì„ íƒ", list(model_zoo.keys()), index=0)
        if st.button("GridSearch ì‹¤í–‰"):
            pipe = make_pipeline(model_name)
            grid = param_grids[model_name]
            gs = GridSearchCV(pipe, grid, scoring=scoring, cv=int(cv), n_jobs=-1, refit=True, return_train_score=True)
            with st.spinner("GridSearchCV ì‹¤í–‰ ì¤‘..."):
                gs.fit(X_train, y_train)

            st.subheader("ë² ìŠ¤íŠ¸ ê²°ê³¼")
            st.write("Best Params:", gs.best_params_)
            st.write("Best CV Score:", gs.best_score_)

            y_pred = gs.predict(X_test)
            st.write(f"Test MSE: {mean_squared_error(y_test,y_pred):.6f}")
            st.write(f"Test R2 : {r2_score(y_test,y_pred):.6f}")

            cvres = pd.DataFrame(gs.cv_results_)
            cols = ["rank_test_score","mean_test_score","std_test_score","mean_train_score","std_train_score","params"]
            st.dataframe(cvres[cols].sort_values("rank_test_score").reset_index(drop=True))

# --- 4.9 ì˜ˆì¸¡ ì‹¤í–‰ ---
with tabs[8]:
    st.header("í‰ì  ì˜ˆì¸¡")
    st.subheader("1) ëª¨ë¸ ì„¤ì •")
    model_type2  = st.selectbox('ëª¨ë¸ ì„ íƒ', ['Random Forest', 'Linear Regression'])
    test_size2   = st.slider('í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨', 0.1, 0.5, 0.2, 0.05, key="ts2")
    feature_cols2 = st.multiselect('íŠ¹ì„± ì„ íƒ',
        ['ë‚˜ì´','ë°©ì˜ë…„ë„','ì„±ë³„','ì¥ë¥´','ë°°ìš°ëª…','í”Œë«í¼','ê²°í˜¼ì—¬ë¶€'],
        default=['ë‚˜ì´','ë°©ì˜ë…„ë„','ì¥ë¥´'],
        key="feat2"
    )

    st.markdown("---")
    st.subheader("2) ì˜ˆì¸¡ ì…ë ¥")

    genre_opts    = sorted({g for sub in raw_df['ì¥ë¥´'].dropna().apply(clean_cell_colab) for g in sub})
    plat_opts     = sorted({p for sub in raw_df['í”Œë«í¼'].dropna().apply(clean_cell_colab) for p in sub})
    actor_opts    = sorted(raw_df['ë°°ìš°ëª…'].dropna().unique())
    gender_opts   = sorted(raw_df['ì„±ë³„'].dropna().unique())
    married_opts  = sorted(raw_df['ê²°í˜¼ì—¬ë¶€'].dropna().unique())

    input_age     = st.number_input("ë°°ìš° ë‚˜ì´", 10, 80, 30)
    input_year    = st.number_input("ë°©ì˜ë…„ë„", 2000, 2025, 2021)
    input_gender  = st.selectbox("ì„±ë³„", gender_opts) if gender_opts else st.text_input("ì„±ë³„ ì…ë ¥", "")
    input_genre   = st.multiselect("ì¥ë¥´", genre_opts, default=genre_opts[:1] if genre_opts else [])
    input_actor   = st.selectbox("ë°°ìš°ëª…", actor_opts) if actor_opts else st.text_input("ë°°ìš°ëª… ì…ë ¥", "")
    input_plat    = st.multiselect("í”Œë«í¼", plat_opts, default=plat_opts[:1] if plat_opts else [])
    input_married = st.selectbox("ê²°í˜¼ì—¬ë¶€", married_opts) if married_opts else st.text_input("ê²°í˜¼ì—¬ë¶€ ì…ë ¥", "")
    predict_btn   = st.button("ì˜ˆì¸¡ ì‹¤í–‰")

    if predict_btn:
        # í•™ìŠµ ë°ì´í„°(Colab ì¸ì½”ë”©ê³¼ ë™ì¼)
        X_all = build_X_from_selected(df_mlb, feature_cols2)
        model = RandomForestRegressor(n_estimators=100, random_state=SEED) if model_type2=="Random Forest" else LinearRegression()
        model.fit(X_all, y_all)

        # ì…ë ¥ 1í–‰ ìƒì„±
        user_raw = pd.DataFrame([{
            'ë‚˜ì´': input_age,
            'ë°©ì˜ë…„ë„': input_year,
            'ì„±ë³„': input_gender,
            'ì¥ë¥´': input_genre,     # ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ
            'ë°°ìš°ëª…': input_actor,
            'í”Œë«í¼': input_plat,    # ë¦¬ìŠ¤íŠ¸
            'ê²°í˜¼ì—¬ë¶€': input_married
        }])

        # Colabê³¼ ë™ì¼ ë©€í‹°ë¼ë²¨ transform
        user_mlb = colab_multilabel_transform(user_raw, cols=('ì¥ë¥´','ë°©ì˜ìš”ì¼','í”Œë«í¼'))
        user_X = build_X_from_selected(user_mlb, feature_cols2)

        # í•™ìŠµ Xì™€ ì»¬ëŸ¼ ì •í•©
        for c in X_all.columns:
            if c not in user_X.columns:
                user_X[c] = 0
        user_X = user_X[X_all.columns]

        pred = model.predict(user_X)[0]
        st.success(f"ğŸ’¡ ì˜ˆìƒ í‰ì : {pred:.2f}")
